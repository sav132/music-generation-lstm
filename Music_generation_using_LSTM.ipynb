{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of music generation using LSTM(with explanations).ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "gLuDbna0qxto",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "import glob\n",
        "from tqdm import tqdm\n",
        "import sys\n",
        "import os\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mg3jB-RQrNmI",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "135eb6a4-f037-488a-d78a-c55076547e80",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1528287048122,
          "user_tz": -330,
          "elapsed": 10343,
          "user": {
            "displayName": "Savio rajan k",
            "photoUrl": "//lh4.googleusercontent.com/-zx6u5-u85bI/AAAAAAAAAAI/AAAAAAAAAIM/jJZxtl37FdE/s50-c-k-no/photo.jpg",
            "userId": "109249337649573526738"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, LSTM\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils\n",
        "from keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "IRhdTX2AK_IR",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# Loading the data.\n",
        "paths = glob.glob('data/midi_abc/*.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Zyc7wXM9MKkA",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "6d851828-c53b-4bec-836a-ff047a9dbac4",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1528287073858,
          "user_tz": -330,
          "elapsed": 849,
          "user": {
            "displayName": "Savio rajan k",
            "photoUrl": "//lh4.googleusercontent.com/-zx6u5-u85bI/AAAAAAAAAAI/AAAAAAAAAIM/jJZxtl37FdE/s50-c-k-no/photo.jpg",
            "userId": "109249337649573526738"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "paths"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['data/midi_abc/reelsa-c.txt',\n",
              " 'data/midi_abc/reelsu-z.txt',\n",
              " 'data/midi_abc/slip.txt',\n",
              " 'data/midi_abc/ashover.txt',\n",
              " 'data/midi_abc/playford.txt',\n",
              " 'data/midi_abc/xmas.txt',\n",
              " 'data/midi_abc/reelsm-q.txt',\n",
              " 'data/midi_abc/hpps.txt',\n",
              " 'data/midi_abc/morris.txt',\n",
              " 'data/midi_abc/waltzes.txt',\n",
              " 'data/midi_abc/jigs.txt',\n",
              " 'data/midi_abc/reelsh-l.txt',\n",
              " 'data/midi_abc/reelsr-t.txt',\n",
              " 'data/midi_abc/reelsd-g.txt']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "F2TjsGTzMn4t",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# add them into one big string\n",
        "data = \"\"\n",
        "for path in paths:\n",
        "    data += (open(path).read())\n",
        "\n",
        "data_split = []\n",
        "tmp = \"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_erpfeAvQWqT",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Split the data at every 'X' so that it is easier to train is small pieces. Also remove newlines.\n",
        "for i in data:\n",
        "    if i=='X' and tmp!=\"\":\n",
        "        tmp = tmp.rstrip()\n",
        "        data_split.append(tmp)\n",
        "        tmp=\"\"\n",
        "tmp += i"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YfL6CeAzMnTA",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "del data_split[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HMJivL9LRSVV",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "for i in data_split:\n",
        "    data += i"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yb8kp1PYRio3",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "#Proceed to creating a dictionary with which  can convert characters to integers and vice versa (basically vectorization)\n",
        "chars = sorted(list(set(data)))\n",
        "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
        "int_to_char = dict((i, c) for i, c in enumerate(chars))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0r0-pDM0Rozh",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "n_chars = len(data)\n",
        "n_vocab = len(chars)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LzLphoyYSnXQ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "415e3052-36d8-4456-bc28-07fdef99bfd8",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1528287123816,
          "user_tz": -330,
          "elapsed": 1107,
          "user": {
            "displayName": "Savio rajan k",
            "photoUrl": "//lh4.googleusercontent.com/-zx6u5-u85bI/AAAAAAAAAAI/AAAAAAAAAIM/jJZxtl37FdE/s50-c-k-no/photo.jpg",
            "userId": "109249337649573526738"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "n_chars \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "452499"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "metadata": {
        "id": "xNu2OBwhSbPB",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# The sequences have a length of 100 characters\n",
        "seq_length = 100\n",
        "\n",
        "dataX = []\n",
        "dataY = []\n",
        "for i in range(0, n_chars - seq_length, 1):\n",
        "\tseq_in = data[i:i + seq_length]\n",
        "\tseq_out = data[i + seq_length]\n",
        "\tdataX.append([char_to_int[char] for char in seq_in])\n",
        "\tdataY.append(char_to_int[seq_out])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gfVPeVJ8VsSv",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "2b2b5d3b-81a4-4f16-d994-40e0d1a60f20",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1528287136629,
          "user_tz": -330,
          "elapsed": 1079,
          "user": {
            "displayName": "Savio rajan k",
            "photoUrl": "//lh4.googleusercontent.com/-zx6u5-u85bI/AAAAAAAAAAI/AAAAAAAAAIM/jJZxtl37FdE/s50-c-k-no/photo.jpg",
            "userId": "109249337649573526738"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#to find rows and columns\n",
        "rows  = len(dataX)\n",
        "cols = len(dataX[0])\n",
        "print(rows,cols)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "452399 100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "po99bLaYSH_6",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "2c2a16c6-bba0-4f17-98c7-fe21f74763c9",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1528287146331,
          "user_tz": -330,
          "elapsed": 5770,
          "user": {
            "displayName": "Savio rajan k",
            "photoUrl": "//lh4.googleusercontent.com/-zx6u5-u85bI/AAAAAAAAAAI/AAAAAAAAAIM/jJZxtl37FdE/s50-c-k-no/photo.jpg",
            "userId": "109249337649573526738"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "n_samples = len(dataX)\n",
        "X = np.reshape(dataX, (n_samples, seq_length, 1))\n",
        "X.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(452399, 100, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "metadata": {
        "id": "CxLrBho4Tf0F",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "X = X / float(n_vocab)\n",
        "\n",
        "y = np_utils.to_categorical(dataY)  #np.utils.to_categorical is used to convert array of labeled data(from 0 to nb_classes-1) to one-hot vector.\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M4D-5-IQVT3n",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "8dd2dc6d-755a-49a8-f321-12e277ca6dfa",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1528287159356,
          "user_tz": -330,
          "elapsed": 6488,
          "user": {
            "displayName": "Savio rajan k",
            "photoUrl": "//lh4.googleusercontent.com/-zx6u5-u85bI/AAAAAAAAAAI/AAAAAAAAAIM/jJZxtl37FdE/s50-c-k-no/photo.jpg",
            "userId": "109249337649573526738"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(452399, 100, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "metadata": {
        "id": "9mbOqT11XUhl",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Building the Keras model\n",
        "model = Sequential()\n",
        "model.add(LSTM(512, input_shape=(X.shape[1], X.shape[2]), return_sequences=True)) # Since there is more than one LSTM layer we need to return the sequences\n",
        "model.add(Dropout(0.2)) \n",
        "model.add(LSTM(512))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "62TyDhCWdj2g",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OJIjCBzVdOPe",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "if os.path.isfile('best_weights.hdf5'):\n",
        "\tmodel.load_weights('best_weights.hdf5')\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IX_-dcTcdimG",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "filepath = \"/output/weights-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5\" # Saving the model each time it improves\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Qnl42GeJdn5w",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 1556
        },
        "outputId": "bd2dd041-41ed-4843-8fa2-2fa25946eab0",
        "executionInfo": {
          "status": "error",
          "timestamp": 1528194083678,
          "user_tz": -330,
          "elapsed": 31509,
          "user": {
            "displayName": "Savio rajan k",
            "photoUrl": "//lh4.googleusercontent.com/-zx6u5-u85bI/AAAAAAAAAAI/AAAAAAAAAIM/jJZxtl37FdE/s50-c-k-no/photo.jpg",
            "userId": "109249337649573526738"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Fitting the model to the data.\n",
        "model.fit(X, y, epochs=50, batch_size=1024, callbacks=callbacks_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            " 15360/452399 [>.............................] - ETA: 12:45 - loss: 1.2492"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-3054e8af6cd1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1000\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1002\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1003\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1234\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1236\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1237\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2482\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2483\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "gFo75fC9dq9E",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "outputId": "651e2c46-5fff-4d85-9259-ec43c3944b2f",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1528287863055,
          "user_tz": -330,
          "elapsed": 534152,
          "user": {
            "displayName": "Savio rajan k",
            "photoUrl": "//lh4.googleusercontent.com/-zx6u5-u85bI/AAAAAAAAAAI/AAAAAAAAAIM/jJZxtl37FdE/s50-c-k-no/photo.jpg",
            "userId": "109249337649573526738"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "for k in range(5):\n",
        "\tstart = np.random.randint(0, len(dataX)-1)\n",
        "\tcount = 0\n",
        "\tpattern = dataX[start] # Pick up a random character from the dataset to start from.\n",
        "\t\n",
        "\tprediction_string = \"\"\n",
        "\n",
        "\t# Start predicting a sequence of characters.\n",
        "\tfor i in tqdm(range(1000)):\n",
        "\t\tx = np.reshape(pattern, (1, len(pattern), 1)) # Resize the data to fit to the model.\n",
        "\t\tx = x/float(n_vocab)\n",
        "\n",
        "\t\tpred = model.predict(x, verbose=0) # Make prediction\n",
        "\t\tindex = np.argmax(pred) # Get the character with the highest probability\n",
        "\t\tresult = int_to_char[index] # Convert the one index of the character to a char.\n",
        "\t\t#seq_in = [int_to_char[value] for value in pattern] \n",
        "\t\tprediction_string += result # add the result to the prediction string\n",
        "\t\t#sys.stdout.write(result)\n",
        "\t\tpattern.append(index) # Add the predicted character to the pattern that will be fed next time the model.\n",
        "\t\t\t\t\t\t \t  # For example if the pattern is 'abb' and the model predicts 'a'. make sure to change the pattern that\n",
        "\t\t\t\t\t\t \t  # will be fed next to 'abba' and shorten it to fit so it becomes 'bba'.\n",
        "\t\tpattern = pattern[1:len(pattern)]\n",
        "\t\t# Due to the small size of the dataset the model will probably slightly overfit. To counter that and add a bit \n",
        "\t\t# of variation I added something like noise to it's predictions. So I add random paths of the data to force\n",
        "\t\t# the neural network to change the pattern and choose a different not to make the music a bit more interesting.\n",
        "\t\tstart+=np.random.randint(0, 1)\n",
        "\t\tcount+=1\n",
        "\t\tif count%250==0:\n",
        "\t\t\tstart += np.random.randint(-100*i, 100*2*i)\n",
        "\t\t\twhile start+np.random.randint(0, 200) > len(dataX):\n",
        "\t\t\t\tstart = start-np.random.randint(0, 500)\n",
        "\t\t\tpattern.extend(dataX[start][:50])\n",
        "\t\t\tpattern = pattern[50:len(pattern)]\n",
        "\tprint('Done')\n",
        "\n",
        "\t# Write the predictions to a .txt file.\n",
        "\tfl = open('big_pred_'+ str(k) +'.txt', 'w')\n",
        "\tfl.write(prediction_string)\n",
        "print(prediction_string)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [01:46<00:00,  9.35it/s]\n",
            "  0%|          | 1/1000 [00:00<01:45,  9.47it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Done\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [01:46<00:00,  9.43it/s]\n",
            "  0%|          | 1/1000 [00:00<01:45,  9.46it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Done\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [01:45<00:00,  9.49it/s]\n",
            "  0%|          | 1/1000 [00:00<01:46,  9.34it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Done\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [01:45<00:00,  9.47it/s]\n",
            "  0%|          | 1/1000 [00:00<01:44,  9.60it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Done\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [01:45<00:00,  9.49it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Done\n",
            "/2c/2|\"D\"d/2d/2d/2d/2 \"A\"e/2e/2e/2e/2|\"D\"f/2d/2d/2f/2 \"A\"e/2d/2e/2e/2|\\\n",
            "\"D\"f/2d/2d/2f/2 \"A7\"e/2d/2e/2e/2|\"D\"d/2d/2d/2d/2 \"A\"e/2d/2d/2f/2|\n",
            "\"D\"d/2d/2d/2f/2 \"A\"e/2f/2e/2e/2|\"D\"f/2f/2f/2f/2 \"A\"e/2e/2e/2e/2|\\\n",
            "\"D\"f/2d/2d/2f/2 \"A7\"e/2g/2e/2e/2|\"D\"d/2d/2d/2d\"d/2d/2d/2d/2 \"A\"e/2e/2e/2e/2|\"D\"d/2d/2d/2f/2 \"A\"e/2e/2e/2e/2|\\\n",
            "\"D\"d/2d/2d/2f/2 \"A7\"e/2d/2e/2e/2|\"D\"d/2d/2d/2d/2 \"A\"e/2d/2d/2f/2|\n",
            "\"D\"d/2d/2d/2f/2 \"A\"e/2f/2e/2e/2|\"D\"f/2f/2f/2f/2 \"A\"e/2e/2e/2e/2|\\\n",
            "\"D\"f/2d/2d/2f/2 \"A7\"e/2g/2e/2e/2|\"D\"d/2d/2d/2d/2 \"A\"e/d/2 \"D7\"d/2d/2d/2d/2|\n",
            "\"G\"g/2d/2g/2d/2 \"D\"g/2f/2e/2d/2|\"G\"g/2d/2d/2d/2 \"D\"e/2d/2e/2e/2|\\\n",
            "\"G\"g/2d/2d/2d/2 \"A7\"e/2d/2e/2e/2|\"D\"d/2d/2d/2d/2 \"A7\"e/2d/2g/2e/2|\n",
            "\"D\"d/2d/2d/2f/2 \"A\"e/2e/2e/2e/2|\"D\"d/2d/2d/2f/2 \"A\"e/2e/2e/2e/2|\\\n",
            "\"D\"f/2d/2d/2f/2 \"A7\"e/2g/2e/2A/2 AF|\"D\"F/2F/2A/2F/2 F/2F/2F/2F/2|\"D\"F/2F/2A/2F/2 \"D\"A/2A/2F/2F/2|\\\n",
            "\"G\"G/2G/2G/2F/2 \"A7\"A/2F/2F/2F/2|\"D\"D/2D/2D/2F/2 \"A7\"E/2F/2E/2F/2|\n",
            "\"D\"F/2F/2F/2F/2 \"D\"A/2F/2F/2F/2|\"D\"F/2F/2A/2F/2 \"D\"A/2d/2d/2d/2|\\\n",
            "\"G\"B/2d/2d/2d/2 \"A7\"e/2d/2e/2c/2|\"D\"d/2d/2d/2d/\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "-PCAvPuLK3_b",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Convert the .txt files to midi "
      ]
    }
  ]
}